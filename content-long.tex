% include your own content here directly or with more `input`s
\subsection*{Introduction}
\noindent Physics (domain) knowledge embedded into the process of learning a model of the experimental data is an important tool to improve accuracy and learn more efficiently (less training parameters and data).
Efficient machine learning (ML) is a crucial aspect in the high-energy physics (HEP) domain where ML finds one of its most fundamental application in science because of its capacity for extracting the 
most relevant information from highly-dimensional and complex experimental data. However, the big-data challenges faced at the next generation of HEP experimental setups will require ML to be deployed in real-time with stringent system constraints in terms of computational speed, resource usage, and energy consumption -- particularly important when embedded at the edge of the experimental data acquisition workflow -- while retaining accuracy.
This proposal aims at exploring the connection between efficient ML and ``physics-inspired'' neural networks (PINNs), where the highest efficiency can be achieved by reducing both the training dataset as well as the number of model parameters and of (bitwise) operations for a given NN where the latter can be controlled through sparsity and quantization techniques. We will focus on three different scientific domains that share similar real-time system constraints including experiments at the Large Hadron Collider (LHC), neutrino experiments based on Liquid Argon Time Projection Chamber (LArTPC) technology, and accelerator technology applications. We will explore a number of techniques to efficiently embed the physics-knowledge into the learning process such as custom losses, novel learning techniques (knowledge distillation, curriculum, and continual learning), and input data pre-processing for application to both supervised and unsupervised learning tasks. 
Achieving robustness against the typical domain-shift environment of HEP experiments where conditions usually change or evolve over time is another crucial aspect that can be achieved by retaining the most fundamental parameters through embedding the physics knowledge in our models.
At the same time, we will explore methods in which the ML model itself can be interpreted to teach scientists the fundamental laws. Finally, we will focus on generalizable rules in training and evaluating such models which can be applied in other domains.
The project team has historic strength in optimizing artificial intelligence (AI) techniques for edge applications and developing novel data analysis techniques based on physics laws. \textit{Synthesizing the expertise of the team to develop efficient, physics-inspired AI for data-intensive HEP challenges will: infuse the next generation of data-intensive experiments with powerful real-time \textbf{AI for HEP}; drive novel research directions using \textbf{HEP for AI} to relate physics and domain knowledge with efficient computational systems; and develop \textbf{HEP AI Ecosystems} to foster standardized metrics and benchmarks for empowering HEP and AI innovation.}
%\noindent Using domain (physics) knowledge embedded into ML modeling is an important tool to improve performance and learn more efficiently (smaller models and learning with less data). It can also make AI models more interpretable and explainable. Efficient machine learning is an important aspect of data-intensive ML where big data and real-time machine learning with stringent system constraints requires efficient (fast, energy efficient, low power) ML models â€“ particularly important when embedded at the edge and real-time ML is required in the experimental loop and in data readout. This proposal aims to explore the connection
%between efficient machine learning, computational complexity, and ``physics-inspired''
%neural networks (PINNs). We will focus on unsupervised ML techniques of clustering and anomaly detection across a broad range of HEP  collider~\cite{Govorkova:2021utb}, neutrino, and accelerator applications. We will explore a number of techniques for physics-inspired ML such as knowledge distillation, custom losses, and novel architectures to maintain and improve physics performance. For example, in the case of anomaly detection, we can include a prior on the properties of known physics processes which would help to interpret the nature of the anomaly. Embedding this information in our models can also help us understand evolving detector conditions in more compact ML models when anomaly detection is used for data quality monitoring. We will then explore the connection between PINNs and efficient computing architectures. This includes both the number of model parameters and also the number of (bitwise) operations for a given network. This also includes model sparsity and implementation. This can be compared against more brute force methods for optimization such as Neural Architecture Search and Hyperparameter Optimization. We will
%focus on generalizable conclusions which can be applied in other domains. The project team has historic strength in optimized edge AI and developing novel physics analysis techniques.  \textit{Synthesizing the expertise of the team to develop efficient, physics-inspired AI for data-intensive HEP challenges will: infuse the next generation of data-intensive experiments with powerful real-time \textbf{AI for HEP}; drive novel research directions using \textbf{HEP for AI} to relate physics and domain knowledge with efficient computational systems; and develop \textbf{HEP AI Ecosystems} to foster standardized metrics and benchmarks for empowering HEP and AI innovation.}

\subsection*{Physics domains}
\\
% \hline
\noindent \textcolor{red}{General structure for the applications subsections:}
\begin{itemize}
    \item Introduce the problem/application
    \item Why real-time/edge AI is the solution
    \item Which physics information can you take advantage of (for accelerator is the other way around)
    \item What are the deliverable (focus on what's actually doable)
\end{itemize}
% \hline

\section*{Physics-informed ML}
\textcolor{red}{Amir,Michael M.}

\begin{itemize}
\item basic concept
\item gains
\item challenges and how to solve them
\end{itemize}

\section*{Triggering with anomaly detection at the LHC}
\textcolor{red}{Jean-Roch,Jen,Nhan}

Unsupervised ML techniques gained popularity in the recent years as a promising approach that could complement the standard methods used by scientists to analyze the data produced by the proton-proton collisions happening at the CERN Large Hadron Collider (LHC) and collected by its experiments. One of the main goals of the data analysis workflow is to find evidence for new physical phenomena that could answer to fundamental questions about the universe that still remain unanswered today.
While the standard supervised analysis approach specifies a signal hypothesis upfront which thus determines each step of the analysis workflow, an unsupervised learning method, such as anomaly detection, allows to isolate and study ``anomalous'' collision events, i.e. events that are not produced by known physics processes but that could be due instead to unexpected processes not yet seen at colliders. Signal-agnostic searches have been designed in the past but only recently their potential could be significantly enhanced thanks to advances in modern AI~\cite{Govorkova:2021utb}. As studied by the PI in Ref.~\cite{Govorkova:2021utb} the most important recent advances one can take advantage on for this task are on one hand novel neural network architectures such as deep (variational) autoencoders and on the other hand advances in tools that allow one for the first time to deploy these new methods in the real-time data filtering system of the LHC experiments.
At the LHC, 40\,MHz of proton-proton collisions lead to enormous data rates flowing out of each detector, requiring thus analysis and filtering in real time in order to achieve a manageable offline processing rate and storage of $\sim$ 1000 collision events/second. It is possible that a new physics signal would escape detection, simply because the corresponding new physics events would be rejected by the typical set of algorithms designed to perform event filtering in real-time. Traditionally, cut-based selection algorithms have been used for filtering, in order to meet the limited latency- and resource- budget. However, with the advent of tools like hls4ml and \texttt{QKeras}, unsupervised ML alternatives can be explored to improve the sensitivity to such physics processes while maintaining latency and resources in the available budget.  Any tagged anomalous event must be interpretable as understanding the physics behind it can either confirm or reject a new physics discovery claim. For this reason the approach of deploying unsupervised learning in the trigger system must also face the challenge of keeping robustness throughout a long data taking period. As the algorithm will be trained on known physics processes and a range of domains, such knowledge will be exploited in this proposal through the fundamental physics laws.

\section*{On the Edge Deep Learning AI for Tagging and Trigger in Liquid Argon Neutrino Detector}
\textcolor{red}{Christian, Mishra, Wang}

Liquid Argon TPCs (LArTPCs) are being used for many current and planned neutrino experiments at Fermilab. LArTPCs are a transformative technology for neutrino experiments because they enable simultaneous precise tracking and calorimetry. DUNE and SBND both use very low noise front-end electronics and wave form digitizers located in the liquid argon.  Data is streamed without zero suppression to Warm Interface Boards (WIBs) outside the cryostat.  The WIBs combine multiple data streams and transmit the data to the Data Acquisition System, still without zero suppression. Triggers will be implemented in firmware or in software to select data to be written to permanent storage.

Deep learning (DL) algorithms have been developed for identification of the neutrino Argon interactions and for offline analysis in LArTPCs. This proposed work will focus on the development of PINN techniques for implementation on the Edge for, a) tagging neutrino interaction events in the data stream and b) the energy calibration of the Liquid Argon TPC detector and electronics. The AI model will be designed for implementation on one of the new low-power edge-computing platforms optimized for DL applications, which can be directly implemented on the WIB FPGA or attached to the data port of the WIB. The DL models we will implement at the edge will range from performing signal processing to reconstructing clusters representing tracks and particle identification. Applying DL at the edge will help address the huge data volumes produced by LArTPC, the identification of neutrino-interaction events in the data sample, and energy calibration of the detector. 

\section*{Quench detection in superconducting magnets (\textcolor{red}{Vittorio})}

In superconducting magnets, the transition to the resistive state of part of the windings is called quench. Due to the large stored energy quench can be dangerous, and needs to be detected to discharge magnet current as fast as possible. Presently, quench detection systems operate \textit{reactively}, relying on the fast detection of the event while it is happening. 
%This measurement however depends on the quench propagation velocity; in Hight-Temperature-Superconductor (HTS) magnets, this velocity is low, and current QDS techniques limit magnet design. 
We propose to change the paradigm to quench detection by determining in real-time, at the millisecond scale, so-called quench precursors. Precursors are different in shape and length, and extremely difficult to detect with standard techniques though we have shown with early work has shown that ML detection of precursors is possible. 
%We proved however that using machine learning it is possible to detect precursors with good accuracy (~75\%) in acoustic data, developing a prototype in a SIST summer student program. We propose to build on the experience coming from this prototype a complete quench precursors detection system, able to acquire data (voltage, acoustic, optics, electromagnetic) with dedicated hardware, and to detect quench precursors in real-time using machine learning. This will enable to detect quench before its beginning (game-changer in HTS), and also to provide feedback to power supplies to reduce current before quench begins, giving a chance to avoid quench, and reduce training of Low-Temperature-Superconductor magnets.
In this project, we will use the quench detection task to develop an efficient anomaly detection algorithm that can operate quickly, in real-time, to detect quench precursors and also provide insight into to physics of quench events.  The ultimate goal is to better understand magnet quenches, detect quenches before their occurrence, and reduce significant superconducting magnet training times and costs. 


\section*{Scientific benchmarks (\textcolor{red}{Nhan,Vijay})}

As described above, fast, real-time ML at the edge is essential for reducing and filtering scientific data in real-time to accelerate science experimentation, provide automated and accelerated feedback loops, and enable more profound insights. 
Furthermore, HEP accelerators and experiments have strict requirements which greatly surpass needs in industry, fostering more innovative solutions.  
To accelerate real-time scientific edge ML hardware and software solutions, we need well-constrained benchmark tasks with enough specification to be generically applicable and accessible to enable technological innovation.
We will leverage our expertise, including previous work with community and industry leaders MLPerf and TinyML, in providing curated datasets and developing metrics and benchmarks for our ML tasks. This can guide the design of future edge ML hardware for scientific applications capable of meeting the nanosecond to millisecond level latency requirements. 

{\footnotesize
  \bibliographystyle{JHEP}
\bibliography{reference.bib}
}